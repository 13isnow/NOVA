publish time: 2023-12-16T01:35:47.000Z  
https://www.yuque.com/rhg37y/fvdi39/amaia5nu3n4ql7f3  
author: 阮一海  
---
搜索【word2vec】

[[NLP] 秒懂词向量Word2vec的本质](https://zhuanlan.zhihu.com/p/26306795)

📄[word2vec--TensorFlow](https://www.tensorflow.org/text/tutorials/word2vec#skip-gram_and_negative_sampling)

依据上面这篇文章

```python
f1 = open('out_demo2.txt', encoding='utf-8')#这里的out_demo2是分好词的文件
for line in f1:
    tokens = list(line.lower().split())
    print(len(tokens), end='
')
    vocab, index = {}, 1  # start indexing from 1
    vocab['<pad>'] = 0  # add a padding token
    for token in tokens:
        if token not in vocab:
            vocab[token] = index
        index += 1
        vocab_size = len(vocab)
        print(vocab)
        inverse_vocab = {index: token for token, index in vocab.items()}
        print(inverse_vocab)
        example_sequence = [vocab[word] for word in tokens]
        print(example_sequence)

```

<details class="lake-collapse"><summary id="u1a2f2943"><span class="ne-text" style="font-size: 16px">运行结果1</span></summary><p id="uf36852f1" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702168751020-a47aa809-bee7-4ad9-a1c1-3889e26f9ac1.png" width="351" id="u071ce24e" class="ne-image"></p></details>
可以看到编号是有了，但是逐词编排，显然不符合应用场景

（没有基础的人就是这样，这么简单的代码也要慢慢研究）

研究了一段时间python代码，不会捏，再去搜搜看有没有现成的代码让我搬运

说到代码，我决定去github上找开源

搜索【匹配索引 Language:Python】

[ElasticSearch_for_Match/code/main.py at master · JovenChu/ElasticSearch_for_Match](https://github.com/JovenChu/ElasticSearch_for_Match/blob/master/code/main.py)

楽，应该用英语的，搜索【index matching Language:Python】

然而，github上全是项目之类的大型代码，让一个新手去里面找要用到的代码还是太苛刻了

但是经过缓慢的查找，我还是研究出了一点东西

```python
f1 = open('out_demo2.txt', encoding='utf-8')
vocab, index = {}, 1  # start indexing from 1
vocab['<pad>'] = 0  # add a padding token
for line in f1:
    if line not in vocab:
        line = line.replace('
', '')
        vocab[line] = index
        index += 1
vocab_size = len(vocab)
print(vocab)
inverse_vocab = {index: line for line, index in vocab.items()}
print(inverse_vocab)
f1.close()
```

<details class="lake-collapse"><summary id="u95318f54"><span class="ne-text" style="font-size: 16px">运行结果2</span></summary><p id="ud02da464" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702175175590-22607003-155d-4c52-b681-7e58fb55d5b1.png" width="1608" id="u7b787eba" class="ne-image" style="font-size: 16px"></p></details>
现在期望的是可以构建词向量，以便后续匹配

我也许可以让AI实现一下

<details class="lake-collapse"><summary id="u14c02405"><span class="ne-text" style="font-size: 16px">AI对话</span></summary><h1 id="fLh8B"><span class="ne-text">USER：</span></h1><p id="u6c5f81f7" class="ne-p"><span class="ne-text">请帮我完善这份代码</span></p><pre data-language="python" id="BsAz8" class="ne-codeblock language-python"><code>f1 = open('out_demo2.txt', encoding='utf-8')
vocab, index = {}, 1  # start indexing from 1
vocab['&lt;pad&gt;'] = 0  # add a padding token
for line in f1:
    if line not in vocab:
        line = line.replace('
', '')
        vocab[line] = index
        index += 1
vocab_size = len(vocab)
print(vocab)
inverse_vocab = {index: line for line, index in vocab.items()}
print(inverse_vocab)
tokens = []
for line in f1:
    line = line.replace('
', '')
    print(line)
    tokens.append(line)
print(tokens)
example_sequence = [vocab[word] for word in tokens]
print(example_sequence)</code></pre><h1 id="mGAb6"><span class="ne-text">ANSWER：</span></h1><pre data-language="python" id="LyhuA" class="ne-codeblock language-python"><code>f1 = open('out_demo2.txt', encoding='utf-8')
vocab, index = {}, 1  # start indexing from 1
vocab['&lt;pad&gt;'] = 0  # add a padding token

for line in f1:
    line = line.strip()  # Remove leading/trailing whitespace
    if line not in vocab:
        vocab[line] = index
        index += 1

f1.close()  # Close the file after reading

vocab_size = len(vocab)
print(vocab)

inverse_vocab = {index: line for line, index in vocab.items()}
print(inverse_vocab)

tokens = []
f1 = open('out_demo2.txt', encoding='utf-8')  # Open the file again to read from the beginning

for line in f1:
    line = line.strip()
    tokens.append(line)

f1.close()  # Close the file after reading

print(tokens)

example_sequence = [vocab[word] for word in tokens]
print(example_sequence)</code></pre><p id="u10a9da75" class="ne-p"><br></p><p id="u611ea1a4" class="ne-p"><span class="ne-text">In the code you provided, I made a few modifications to improve its functionality:</span></p><p id="u33c3b29e" class="ne-p"><br></p><ol class="ne-ol"><li id="u56da011a" data-lake-index-type="0"><span class="ne-text">Added </span><code class="ne-code"><span class="ne-text">line.strip()</span></code><span class="ne-text"> to remove leading and trailing whitespace from each line read from the file.</span></li><li id="u80475182" data-lake-index-type="0"><span class="ne-text">Closed the file after reading it using </span><code class="ne-code"><span class="ne-text">f1.close()</span></code><span class="ne-text"> to free up system resources.</span></li><li id="u4cbc76dd" data-lake-index-type="0"><span class="ne-text">Reopened the file before the second loop to read from the beginning again.</span></li><li id="u539128f6" data-lake-index-type="0"><span class="ne-text">Removed the unnecessary line </span><code class="ne-code"><span class="ne-text">line = line.replace('
', '')</span></code><span class="ne-text"> since </span><code class="ne-code"><span class="ne-text">line.strip()</span></code><span class="ne-text"> already removes newline characters.</span></li></ol><p id="ud7b41913" class="ne-p"><br></p><p id="ud9a2b982" class="ne-p"><span class="ne-text">These changes should help ensure that the code functions as intended. Let me know if you have any further questions or if there's anything else I can assist you with.</span></p><p id="u442f6022" class="ne-p"><span class="ne-text"></span></p><h1 id="myG6w"><span class="ne-text">USER:</span></h1><p id="uf71d473b" class="ne-p"><span class="ne-text">我希望可以遍历整篇文章，并通过vocab给重复出现的词添加索引</span></p><p id="u8cee985e" class="ne-p"><span class="ne-text"></span></p><h1 id="i2voz"><span class="ne-text">ANSWER：</span></h1><pre data-language="python" id="Y2wQr" class="ne-codeblock language-python"><code>f1 = open('out_demo2.txt', encoding='utf-8')
vocab, index = {}, 1  # start indexing from 1
vocab['&lt;pad&gt;'] = 0  # add a padding token

for line in f1:
    line = line.strip()  # Remove leading/trailing whitespace
    if line not in vocab:
        vocab[line] = index
        index += 1

f1.close()  # Close the file after reading

vocab_size = len(vocab)
print(vocab)

inverse_vocab = {index: line for line, index in vocab.items()}
print(inverse_vocab)

tokens = []
f1 = open('out_demo2.txt', encoding='utf-8')  # Open the file again to read from the beginning

for line in f1:
    line = line.strip()
    tokens.append(line)

f1.close()  # Close the file after reading

print(tokens)

example_sequence = [vocab[word] for word in tokens]
print(example_sequence)</code></pre><p id="u839a30a5" class="ne-p"><br></p><p id="u19448599" class="ne-p"><span class="ne-text">这段代码可以遍历整篇文章，并使用</span><code class="ne-code"><span class="ne-text">vocab</span></code><span class="ne-text">为重复出现的词添加索引。它首先打开文件并创建一个空的词汇表（</span><code class="ne-code"><span class="ne-text">vocab</span></code><span class="ne-text">）和索引（</span><code class="ne-code"><span class="ne-text">index</span></code><span class="ne-text">）变量。然后，它逐行读取文章并去除每行的首尾空格。如果当前行不在词汇表中，它会将该行添加到词汇表，并为其分配一个索引。接下来，它关闭文件，并重新打开文件以从头开始读取。然后，它将每行添加到</span><code class="ne-code"><span class="ne-text">tokens</span></code><span class="ne-text">列表中，并使用词汇表中的索引替换每个单词。最后，它打印词汇表、反向词汇表和替换后的</span><code class="ne-code"><span class="ne-text">tokens</span></code><span class="ne-text">列表。</span></p><p id="u262d691a" class="ne-p"><br></p><p id="u498a228b" class="ne-p"><span class="ne-text">请注意，这段代码并没有对文章进行分词处理，它将整行文本视为一个单词。如果你希望对文章进行分词处理，你可以使用适当的分词工具或库来替换代码中的行处理部分。</span></p><p id="u4a783e87" class="ne-p"><span class="ne-text"></span></p></details>
在经过小小修改

```python
#接上端代码
tokens = []
f1 = open('out_demo2.txt', encoding='utf-8')  # Open the file again to read from the beginning
for line in f1:
    line = line.strip()
    tokens.append(line)
f1.close()  # Close the file after reading
example_sequence = [vocab[word] for word in tokens]
print(example_sequence)

```

<details class="lake-collapse"><summary id="u3ec636ad"><span class="ne-text" style="font-size: 16px">运行结果3</span></summary><p id="ue8f11546" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702175973218-36bc589e-8c55-4e6d-8518-49598f45df98.png" width="1608" id="u57a7e088" class="ne-image"></p></details>
