publish time: 2023-12-16T01:35:24.000Z  
https://www.yuque.com/rhg37y/fvdi39/ks3rqp3prwg8m9le  
author: 阮一海  
---
 ![](https://cdn.nlark.com/yuque/0/2023/png/38709574/1702339642271-4c933170-067a-43fe-b581-9fa16ccb47da.png)

可恶，隔了两天没处理任务，看不懂代码了QAQ

```python
import jieba
from gensim import corpora, models, similarities


dictionary = corpora.Dictionary()
index = similarities.SparseMatrixSimilarity([], num_features=12)
tfidf = models.TfidfModel([[(0, 0)]])


# 分词与去停用词, 构建词典
def build_dic():
    global dictionary
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    stop_list = open('cn_stopwords.txt', encoding='utf-8')  # 停用词文件
    texts = []
    stopwords = {}.fromkeys([line.rstrip() for line in stop_list])
    for line in source_file:
        words = jieba.cut(line, cut_all=False)
        for word in words:
            word = word.replace('
', '').replace(' ', '')
            if word not in stopwords:
                if word not in ['']:
                    texts.append([word])
    source_file.close()
    stop_list.close()
    dictionary = corpora.Dictionary(texts)


# TF-IDF转换
def create_tfidf():
    global index, tfidf
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    new_vec = []
    for line in source_file:
        sentences = jieba.cut(line, cut_all=False)
        new_vec.append(dictionary.doc2bow(sentences))

    tfidf = models.TfidfModel(new_vec)
    index = similarities.SparseMatrixSimilarity(tfidf[new_vec], num_features=12)
    source_file.close()


# 求相似度
def get_similarity():
    global index
    doc = ["学生", "活动"]
    vec_bow = dictionary.doc2bow(doc)
    sims = index[tfidf[vec_bow]]
    print(list(enumerate(sims)))


if __name__ == "__main__":
    build_dic()
    create_tfidf()
    get_similarity()
```

一晚上，整整5小时我都没有找到bug在哪里，玉玉了

![](https://cdn.nlark.com/yuque/0/2023/png/38709574/1702567196950-5cdbd962-36bf-4413-9588-491de1c68ecd.png)

[TF-IDF（2）](https://nova.yuque.com/rhg37y/fvdi39/cknccilis7ak6zgr)最后出现的那个问题并没有解决，当时出了结果只是因为它恰巧是一个特例



<details class="lake-collapse"><summary id="ubdceeb03"><span class="ne-text">记录一下自己的猜测试错过程</span></summary><p id="u448b5db8" class="ne-p"><span class="ne-text">1，依循老师的思路，是内存太大了？把代码拆解成一个个函数试试	</span><span data-color="0" id="LGvPm" class="ne-label">×</span><span class="ne-text"></span></p><p id="uad4c9a3a" class="ne-p"><span class="ne-text">2，ASCII编码有问题？换成utf-8试试	</span><span data-color="0" id="jfM0p" class="ne-label">×</span></p><p id="u8dfd307e" class="ne-p"><span class="ne-text">3，有一些空值，如 [], &quot;&quot;，难道我用的函数处理不了他们？	</span><span data-color="0" id="a1wsX" class="ne-label">×</span></p><p id="ufdb66587" class="ne-p"><span class="ne-text">4，求助AI，AI提供了一些思路	</span><span data-color="0" id="SKLa9" class="ne-label">×</span></p><p id="ue006cef7" class="ne-p"><span class="ne-text">5，</span><span class="ne-text" style="color: #601BDE">index搭建有问题</span><span class="ne-text">，调整一下它调用的数据类型，比如它本来调用的参数类型是list[list[list[tuple[int, int]]]]类型，我来排列组合增删修改一下	</span><span data-color="0" id="gQ0k8" class="ne-label">×</span></p><p id="u0b695de1" class="ne-p"><span class="ne-text">6，再次搜索报错代码的意思，指针错误？断点一行行文档查	</span><span data-color="0" id="rnsvQ" class="ne-label">×</span></p><p id="u7dedd482" class="ne-p"><span class="ne-text">7，不会是我用的文档太老了吧（2017年的），多搜索一些，看看有没有类似教程	</span><span data-color="0" id="sy8Uw" class="ne-label">×</span><span class="ne-text"></span></p><p id="u335f50f3" class="ne-p"><span class="ne-text">8，经与作者的文档逐字比对，发现作者的文档矩阵是（int，double）类型，而我的是（int，int）类型，试着改改（死马当活马医……）</span><span data-color="0" id="dmM9w" class="ne-label">×</span></p></details>
期间还有反复的print各种变量，期待着发现哪处我漏掉的细节，还有些琐碎的思路与修改我也忘了



最后我再次<font style="color:#601BDE;">求助于AI</font>，耐下性子尝试一步步询问

<details class="lake-collapse"><summary id="u0610c75d"><span class="ne-text">这是失败的上一次，可以对比一下</span></summary><p id="uee915511" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702689437625-82961015-7152-4e6c-a098-1bb1369e9fd8.png" width="1295" id="ue9d85c6b" class="ne-image"></p></details>
<details class="lake-collapse"><summary id="u731bac2a"><span class="ne-text">本次对话</span></summary><p id="u6f4486e2" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702689545409-8e4fb1ef-d991-4744-8087-23ca56fe3b27.png" width="1270" id="ue1b5670f" class="ne-image"></p></details>
它提到一个被我之前忽视的一点（或许我忽视它也有一点老师的原因←_←）



![](https://cdn.nlark.com/yuque/0/2023/png/38709574/1702689751494-eb288ea0-1869-4972-976d-ffffe43a9471.png)前面没有搞清楚这个参数的用处，这次我搜索查询一下【num_features=12】

[基于gensim TFIDF模型 的文章推荐算法-CSDN博客](https://blog.csdn.net/qq_34333481/article/details/85327090)

![](https://cdn.nlark.com/yuque/0/2023/png/38709574/1702689894347-08bb89f6-facf-4afd-9415-8b8c8acab42a.png)

我把这串代码替换上去

```python
import jieba
from gensim import corpora, models, similarities


dictionary = corpora.Dictionary()
new_vec = []
tfidf = models.TfidfModel([[]])


# 分词与去停用词, 构建词典
def build_dic():
    global dictionary
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    stop_list = open('cn_stopwords.txt', encoding='utf-8')  # 停用词文件
    texts = []
    stopwords = {}.fromkeys([line.rstrip() for line in stop_list])
    for line in source_file:
        words = jieba.cut(line, cut_all=False)
        for word in words:
            word = word.replace('
', '').replace(' ', '')
            if word not in stopwords:
                if word not in ['']:
                    texts.append([word])
    source_file.close()
    stop_list.close()
    dictionary = corpora.Dictionary(texts)


# TF-IDF转换
def create_tfidf():
    global new_vec, tfidf
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    new_vec = []
    for line in source_file:
        new_vec.append(dictionary.doc2bow(jieba.cut(line, cut_all=False)))
    while [] in new_vec:
        new_vec.remove([])
    tfidf = models.TfidfModel(new_vec)
    source_file.close()


# 求相似度
def get_similarity():
    doc = ["学生", "活动"]
    vec_bow = dictionary.doc2bow(doc)
    index = similarities.SparseMatrixSimilarity(tfidf[new_vec], num_features=len(dictionary.token2id.keys()))
    sims = index[tfidf[vec_bow]]
    print(list(enumerate(sims)))


if __name__ == "__main__":
    build_dic()
    create_tfidf()
    get_similarity()

```

终于成功了

😀😃😄😁😆😅🤣😂🙂🙃😉😊😍😇😘😗😚😙😋😛😜😝🤑🤗🤔🤐😐😑😶😏😒🙄😬🤥😌😔😪🤤😴😷🤒🤕🤢🤧😵🤠😎🤓😕🙁😟😮😯😲😳😦😧😨😰😥😢😭😱😖😣😞😓😩😫😤😡😠😈👿💀☠️💩🤡👹👺👻👽👾🤖😺😸😹😻😼😽🙀😿😾🙈🙉🙊💋💌💘💝💖💗💓💞💕💟❣️💔❤️💛💚💙💜🖤💯💢💥💫💦💨🕳️💣💬👁️‍🗨️🗨️🗯️💭💤

<details class="lake-collapse"><summary id="u8e5a2c1b"><span class="ne-text">效果展示</span></summary><p id="ue85fe54a" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2023/png/38709574/1702690083546-9dbde161-1201-4b0a-abb9-247eefb51fda.png" width="827" id="u04f6123f" class="ne-image"></p></details>
:::warning
<font style="color:#601BDE;">解释一下，这是一个列表，里面是若干元组，形如(a, b)。其中a指的是语句编号，比如txt的第5句话，那么a==5；b是语句相似度，比如我输入关键词[" 学生", "活动"]，它会比较每句话与这组关键词的tfidf值（一种对文本的量化方式），给出两者的相似度。</font>

<font style="color:#601BDE;">如此，我就可以排序了，把相似度最高的几句话列出来，实现索引！</font>

:::



