publish time: 2023-12-16T02:00:57.000Z  
https://www.yuque.com/rhg37y/fvdi39/pnzt8wueh8x6avt6  
author: 阮一海  
---
参考新找的这篇文章

[基于gensim TFIDF模型 的文章推荐算法-CSDN博客](https://blog.csdn.net/qq_34333481/article/details/85327090)

```python
related_doc_indices = sims.argsort()[:-6:-1]
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    texts = []
    for line in source_file:
        texts.append(line)
    for i in related_doc_indices[::-1]:
        print(texts[i])
```



加了一点点小优化后的代码

```python
import jieba
from gensim import corpora, models, similarities


dictionary = corpora.Dictionary()
new_vec = []
tfidf = models.TfidfModel([[]])


# 分词与去停用词, 构建词典
def build_dic():
    global dictionary
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    # 对了我debug时把txt编码改成utf-8了，要用老师给的txt记得把后面的“encoding="utf-8"”删去，包括后面的文件调用
    stop_list = open('cn_stopwords.txt', encoding='utf-8')  # 停用词文件
    texts = []
    stopwords = {}.fromkeys([line.rstrip() for line in stop_list])
    for line in source_file:    
        words = jieba.cut(line, cut_all=False)  # jieba分词
        for word in words:
            word = word.replace('
', '').replace(' ', '')  # 为了美观，删一些没用的空值
            if word not in stopwords:
                if word not in ['']:
                    texts.append([word])
    source_file.close()
    stop_list.close()
    dictionary = corpora.Dictionary(texts)  # 构建词典


# TF-IDF转换
def create_tfidf():
    global new_vec, tfidf
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    new_vec = []
    for line in source_file:
        new_vec.append(dictionary.doc2bow(jieba.cut(line, cut_all=False)))
    while [] in new_vec:
        new_vec.remove([])
    tfidf = models.TfidfModel(new_vec)  # 得到tfidf数据
    source_file.close()


# 相似度匹配查询
def get_similarity():
    doc = [input("输入查询关键词：")]
    vec_bow = dictionary.doc2bow(doc)   
    index = similarities.SparseMatrixSimilarity(tfidf[new_vec], num_features=len(dictionary.token2id.keys()))
    sims = index[tfidf[vec_bow]]
    related_doc_indices = sims.argsort()[:-6:-1]    # 输出相似度最高的五句话的编号
    print(related_doc_indices)
    source_file = open('南京大学学生手册2023版.txt', encoding="utf-8")  # 源文件
    texts = []
    for line in source_file:
        texts.append(line)
    for i in related_doc_indices[::-1]:
        print(texts[i-1], texts[i], texts[i+1])


if __name__ == "__main__":
    build_dic()
    create_tfidf()
    get_similarity()

```

![](https://cdn.nlark.com/yuque/0/2023/png/38709574/1702691794686-ac1a0470-7062-4501-9d16-61102b0c9321.png)

好像匹配的没有那么精确，但我要摆烂了！！

